{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcfbGhs1eJF6"
   },
   "source": [
    "# Document Q&A With Retrieval Augmented Generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghQ2aBsbnMyn"
   },
   "source": [
    "---\n",
    "\n",
    "* Author: Gabe Rives-Corbett\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates how to implement Retrieval Augmented Generation with basic automated evaluation. It demonstrates the impact that chunk size, overlap and context length have on model outputs. The notebook will create a Q&A system that allows you to find information based on the Google Cloud Generative AI documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsW5tPDRkT4m"
   },
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jx1FQVAokWVb"
   },
   "source": [
    "#### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJFw23w1kYVj"
   },
   "outputs": [],
   "source": [
    "%pip install -q --upgrade --user google-cloud-aiplatform==1.36.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "#### Restart current runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRvKdaPDTznN",
    "outputId": "154a71b5-f302-4f53-ed2f-b3e5fef9195b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "import time\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jwsaMQYkZm8"
   },
   "source": [
    "#### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, you will need to authenticate your environment. To do this, run the new cell below. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikOmH4doxOFs"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-h0ba4rmkpKW"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YLUml_s7iqBc"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.linalg\n",
    "import vertexai\n",
    "\n",
    "from google.api_core import retry\n",
    "from vertexai.language_models import TextEmbeddingModel, TextGenerationModel\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure notebook environment\n",
    "\n",
    "### Set the following constants to reflect your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project information\n",
    "PROJECT_ID = \"gcp-generative-ai\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKBmi2BMk_OU"
   },
   "source": [
    "## Scrape text from GCP GenAI VertexAI documentation via List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXG6N0WclGsQ"
   },
   "source": [
    "Retrieve list of Google documentation URLs from a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tXHmC10IitET"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/search/retrieval-augmented-generation/examples/URLs.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # The request was successful, and the content is in response.text\n",
    "    content = response.text\n",
    "\n",
    "URLS = [line.strip() for line in content.splitlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-Ly0yNVlReK"
   },
   "source": [
    "Parse the HTML and extract relevant plain text sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hMD6Qz_TkFMG"
   },
   "outputs": [],
   "source": [
    "# Given a Google documentation URL, retrieve a list of all text chunks within h2 sections\n",
    "def get_sections(url: str) -> list[str]:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    sections = []\n",
    "    paragraphs = []\n",
    "\n",
    "    body_div = soup.find(\"div\", class_=\"devsite-article-body\")\n",
    "    if body_div:  # Check if body_div is not None\n",
    "        for child in body_div.findChildren():\n",
    "            if child.name == \"p\":\n",
    "                paragraphs.append(child.get_text().strip())\n",
    "            if child.name == \"h2\":\n",
    "                sections.append(\" \".join(paragraphs))\n",
    "                break\n",
    "\n",
    "    for header in soup.find_all(\"h2\"):\n",
    "        paragraphs = []\n",
    "        nextNode = header.nextSibling\n",
    "        while nextNode:\n",
    "            if isinstance(nextNode, Tag):\n",
    "                if nextNode.name in {\"p\", \"ul\"}:\n",
    "                    paragraphs.append(nextNode.get_text().strip())\n",
    "                elif nextNode.name == \"h2\":\n",
    "                    sections.append(\" \".join(paragraphs))\n",
    "                    break\n",
    "            nextNode = nextNode.nextSibling\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "poNdlLf4kFp5"
   },
   "outputs": [],
   "source": [
    "all_text = [t for url in URLS for t in get_sections(url) if t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wy-qw-xslYpX"
   },
   "source": [
    "Note that most documents are relatively short, but some are thousands of characters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DSkdu30tuNbY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': '0'}>]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_lengths = [len(t) for t in all_text]\n",
    "pd.DataFrame(text_lengths).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r00cIHIVlj4E"
   },
   "source": [
    "## Create vector store\n",
    "\n",
    "Start by initializing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "embeddings_model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\n",
    "text_model = GenerativeModel(\"gemini-1.5-flash-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEYwgmPxlokS"
   },
   "source": [
    "Create some helper functions for vector similarity and chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SStUcSPluhvw"
   },
   "outputs": [],
   "source": [
    "# Separates seq into multiple chunks in the specified size with the specified overlap\n",
    "def split_overlap(seq, size, overlap):\n",
    "    if len(seq) <= size:\n",
    "        return [seq]\n",
    "    return [\"\".join(x) for x in zip(*[seq[i :: size - overlap] for i in range(size)])]\n",
    "\n",
    "\n",
    "# Compute the cosine similarity of two vectors, wrap as returned function to make easier to use with Pandas\n",
    "def get_similarity_fn(query_vector):\n",
    "    def fn(row):\n",
    "        return np.dot(row, query_vector) / (\n",
    "            numpy.linalg.norm(row) * numpy.linalg.norm(query_vector)\n",
    "        )\n",
    "\n",
    "    return fn\n",
    "\n",
    "\n",
    "# Retrieve embeddings from the specified model with retry logic\n",
    "@retry.Retry(timeout=300.0)\n",
    "def get_embeddings(text):\n",
    "    return embeddings_model.get_embeddings([text])[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70aXFPhJmCM8"
   },
   "source": [
    "Create the vector store, we are using a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0cEJeeGIgFxc"
   },
   "outputs": [],
   "source": [
    "def create_vector_store(texts, chunk_size, overlap):\n",
    "    vector_store = pd.DataFrame()\n",
    "    # Insert the individual texts into the vector store\n",
    "    vector_store[\"texts\"] = list(\n",
    "        itertools.chain(*[split_overlap(t, chunk_size, overlap) for t in texts])\n",
    "    )\n",
    "\n",
    "    # Create embeddings from those texts\n",
    "    vector_store[\"embeddings\"] = (\n",
    "        vector_store[\"texts\"].progress_apply(get_embeddings).apply(np.array)\n",
    "    )\n",
    "\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ifp-Y_kryXJ3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875f11a16a6c439cbd5e00da4df173cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CHUNK_SIZE = 400\n",
    "OVERLAP = 50\n",
    "\n",
    "vector_store = create_vector_store(all_text, CHUNK_SIZE, OVERLAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ORlMIcEw0LVW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This beginner's guide introduces you to the co...</td>\n",
       "      <td>[-0.01910548098385334, 0.04027912765741348, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In order for generative AI models to generate ...</td>\n",
       "      <td>[-0.06555181741714478, 0.03770160302519798, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>el. On\\nVertex AI, you can customize your mode...</td>\n",
       "      <td>[-0.04964718222618103, 0.016928546130657196, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owered by a generative AI model, the model\\nne...</td>\n",
       "      <td>[-0.04946590214967728, 0.05451052635908127, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offensive or insensitive. To maintain safety ...</td>\n",
       "      <td>[-0.015146843157708645, 0.07577483355998993, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  \\\n",
       "0  This beginner's guide introduces you to the co...   \n",
       "1  In order for generative AI models to generate ...   \n",
       "2  el. On\\nVertex AI, you can customize your mode...   \n",
       "3  owered by a generative AI model, the model\\nne...   \n",
       "4   offensive or insensitive. To maintain safety ...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.01910548098385334, 0.04027912765741348, -0...  \n",
       "1  [-0.06555181741714478, 0.03770160302519798, -0...  \n",
       "2  [-0.04964718222618103, 0.016928546130657196, -...  \n",
       "3  [-0.04946590214967728, 0.05451052635908127, -0...  \n",
       "4  [-0.015146843157708645, 0.07577483355998993, -...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### push vector store to GCS bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs://dev_vector_store\n",
    "# embed_GCP_documentation_jc.parquet\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "# ... (Load your DataFrame and potentially convert to vectors)\n",
    "\n",
    "vector_store.to_parquet('embed_GCP_documentation_jc.parquet') \n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.bucket('dev_vector_store')\n",
    "blob = bucket.blob('embed_GCP_documentation_jc.parquet')\n",
    "blob.upload_from_filename('embed_GCP_documentation_jc.parquet') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load previous vector store from GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Connect to GCS and access the file\n",
    "client = storage.Client()\n",
    "bucket = client.bucket('dev_vector_store') \n",
    "blob = bucket.blob('embed_GCP_documentation_jc.parquet')\n",
    "\n",
    "# 2. Download to a local file (optional but recommended for larger files)\n",
    "blob.download_to_filename('local_vector_store.parquet')\n",
    "\n",
    "# 3. Load into a Pandas DataFrame\n",
    "vector_store = pd.read_parquet('local_vector_store.parquet')\n",
    "\n",
    "# Now you have your vector store loaded into the 'df_vectors' DataFrame\n",
    "print(vector_store.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAJZc3mamQli"
   },
   "source": [
    "## Search the vector store and use for generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdNIXBUimv01"
   },
   "source": [
    "If we send the question to the **foundation model alone, it will hallucinate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = text_model.generate_content(\n",
    "    \"Can you please provide an breakdown of best practices to embed a entire github repo codebase consisting of python files and notebooks?\"\n",
    "    ).text\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZbX1dkAnB6V"
   },
   "source": [
    "Let's solve this problem by retrieving texts from our vector store and telling the model to use them.\n",
    "\n",
    "Search the vector store for relevant texts to insert into the prompt by embedding the query and searching for similar vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "csMpD6498FXL"
   },
   "outputs": [],
   "source": [
    "def get_context(question, vector_store, num_docs):\n",
    "    # Embed the search query\n",
    "    query_vector = np.array(get_embeddings(question))\n",
    "\n",
    "    # Get similarity to all other vectors and sort, cut off at num_docs\n",
    "    top_matched = (\n",
    "        vector_store[\"embeddings\"]\n",
    "        .apply(get_similarity_fn(query_vector))\n",
    "        .sort_values(ascending=False)[:num_docs]\n",
    "        .index\n",
    "    )\n",
    "    top_matched_df = vector_store[vector_store.index.isin(top_matched)][[\"texts\"]]\n",
    "\n",
    "    # Return a string with the top matches\n",
    "    context = \" \".join(top_matched_df.texts.values)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6kDwMEAmnfl"
   },
   "source": [
    "Create a prompt that includes the context and question. Instruct the LLM to only use the context provided to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "KfZnJF470esv"
   },
   "outputs": [],
   "source": [
    "def answer_question(question, vector_store, num_docs=10, print_prompt=False):\n",
    "    context = get_context(question, vector_store, num_docs)\n",
    "    qa_prompt = f\"\"\"Your mission is to answer questions based on a given context.\n",
    "Context: ```{context}```\n",
    "Question: ***{question}***\n",
    "Before you give an answer, make sure it is only from information in the context. If the information is not in the context, just reply \"I don't know the answer to that\". Think step by step.\n",
    "Answer: \"\"\"\n",
    "    if print_prompt:\n",
    "        print(qa_prompt)\n",
    "    result = text_model.generate_content(qa_prompt)\n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96kS0ZU-m6W6"
   },
   "source": [
    "Looking at the fully generated prompt, the context is embedded. Even though the input context is quite messy, the model can now answer factually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90dMoKTr066y"
   },
   "outputs": [],
   "source": [
    "answer_question(\n",
    "    \"What are the best practices to for generative ai in GCP?\",\n",
    "    vector_store,\n",
    "    print_prompt=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "bmfEIvKmnmCb"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a breakdown of the Gemini models available in the Vertex AI context:\n",
       "\n",
       "* **Gemini 1.5 Pro:**  This model is capable of code generation, multi-turn chat, advanced reasoning, and multimodal prompts. \n",
       "* **Gemini 1.5 Flash:** This model is also capable of code generation. \n",
       "* **Gemini 1.0 Pro:** This model can perform code generation tasks.\n",
       "* **Gemini 1.0 Pro Vision:** This is a multimodal model.\n",
       "\n",
       "While the context mentions Gemini models, it doesn't specifically mention which ones are available through the Python SDK. It focuses on the Gemini API and doesn't explicitly state the SDK's model availability. \n",
       "\n",
       "**Therefore, I don't know the answer to that.** \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = answer_question(\n",
    "    \"Please give me a breakdown of the current gemini genai models available via python SDK\", vector_store\n",
    ")\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2A5mQ6Znvmz"
   },
   "source": [
    "## Automated evaluation\n",
    "\n",
    "This implementation of RAG is dependent on the chunk size, the overlap between the chunks, the number of texts passed into the context and the prompt. Let's create a simple prompt to evaluate answers to the questions, this will allow us to tweak the parameters and see how those tweaks compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UB5wB4NR2COn"
   },
   "outputs": [],
   "source": [
    "def eval_answer(question, answer, context):\n",
    "    eval_prompt = f\"\"\"Your mission is to evaluate answers to questions based on a given context. Remember that before you give an answer, you must check to see if it complies with your mission.\n",
    "\n",
    "Context: ```{context}```\n",
    "Question: ***{question}***\n",
    "Answer: \"{answer}\"\n",
    "\n",
    "Respond only with a number from 0 to 5. Think step by step. If the provided answer is not in the context, reply 5 if it is \"I don't know the answer to that\" otherwise reply 0.\n",
    "Relevance: \"\"\"\n",
    "    # Stop sequence to cut the model off after outputting an integer\n",
    "    result = text_model.predict(\n",
    "        eval_prompt, temperature=0, max_output_tokens=1, stop_sequences=[\".\", \" \"]\n",
    "    )\n",
    "    return int(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVMJ9gBPoU-k"
   },
   "source": [
    "Pass several questions in and retrieve the evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyLMJ0u42yxY"
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What release stage is the RLHF tuning feature?\",\n",
    "    \"Can I generate hate speech with text bison?\",\n",
    "    \"What format should my batch prediction in put be in?\",\n",
    "    \"How can I get the number of tokens?\",\n",
    "    \"How do I create a custom style model?\",\n",
    "    \"What is the dimensionality of the vector created by the multimodal model?\",\n",
    "    \"How long will a stable model version be available?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BftOPiMKFm_8"
   },
   "outputs": [],
   "source": [
    "answers = [answer_question(q, vector_store) for q in questions]\n",
    "contexts = [get_context(q, vector_store, 10) for q in questions]\n",
    "idks = [\"I don't know\" in a for a in answers]\n",
    "evals = [\n",
    "    (question, answer, context, eval_answer(question, answer, context), idk)\n",
    "    for question, answer, context, idk in zip(questions, answers, contexts, idks)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zb7VfarNF9W1"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(evals, columns=[\"question\", \"answer\", \"context\", \"score\", \"idk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_X2OjzsodzI"
   },
   "source": [
    "Now adjust the parameters and see the difference in performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWKZent6MNf4"
   },
   "outputs": [],
   "source": [
    "def eval_on_params(chunk_size, overlap, num_docs):\n",
    "    vector_store = create_vector_store(all_text, chunk_size, overlap)\n",
    "    answers = [answer_question(q, vector_store) for q in questions]\n",
    "    contexts = [get_context(q, vector_store, num_docs) for q in questions]\n",
    "    idks = [\"I don't know\" in a for a in answers]\n",
    "    evals = [\n",
    "        (question, answer, context, eval_answer(question, answer, context), idk)\n",
    "        for question, answer, context, idk in zip(questions, answers, contexts, idks)\n",
    "    ]\n",
    "    return pd.DataFrame(\n",
    "        evals, columns=[\"question\", \"answer\", \"context\", \"score\", \"idk\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92rq4ZGerqNX"
   },
   "source": [
    "Smaller chunk sizes takes longer to generate the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuweYEbVgoZt"
   },
   "outputs": [],
   "source": [
    "smaller_context_df = eval_on_params(100, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J38F4YZpi1Bf"
   },
   "outputs": [],
   "source": [
    "smaller_context_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQC7gWPWokJO"
   },
   "source": [
    "A larger context size has created more unknowns. When composing LLMs into systems, carefully consider how to measure the performance of each component in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jmWGmzdgwUI"
   },
   "outputs": [],
   "source": [
    "larger_context_df = eval_on_params(1000, 200, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNOwnFQwizBb"
   },
   "outputs": [],
   "source": [
    "larger_context_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxVrXRR5jRU_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
